{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        stream=None,\n",
    "        level=logging.INFO,\n",
    "        format= '%(asctime)s %(levelname)-8s %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595]\n"
     ]
    }
   ],
   "source": [
    "link_template = 'https://ojs.aaai.org/index.php/AAAI/issue/view/{}'\n",
    "tracks = list(range(576, 596))\n",
    "print(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the proxy\n",
    "proxy = {\n",
    "    'http':  'socks5h://localhost:7890',\n",
    "    'https': 'socks5h://localhost:7890',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_author(link):\n",
    "    resp = requests.get(link, proxies=None)\n",
    "    soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "    articles = soup.find_all('div', class_='obj_article_summary')\n",
    "    titles, authors = [], []\n",
    "    for art in tqdm(articles):\n",
    "        title = art.h3.get_text(strip=True)\n",
    "        author = art.find_all('div', class_='authors')[0].get_text(strip=True)\n",
    "        titles.append(title)\n",
    "        authors.append(author)\n",
    "    return titles, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 13:27:10 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/576\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:11 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/577\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:12 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/578\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:13 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/579\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:13 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/580\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:14 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/581\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:15 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/582\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:16 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/583\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:17 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/584\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:18 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/585\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:19 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/586\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:19 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/587\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:20 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/588\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:21 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/589\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:22 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/590\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:22 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/591\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:23 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/592\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:25 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/593\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:26 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/594\n",
      "0it [00:00, ?it/s]\n",
      "2025-02-24 13:27:27 INFO     https://ojs.aaai.org/index.php/AAAI/issue/view/595\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "titles, authors = [], []\n",
    "for i in tracks:\n",
    "    link = link_template.format(i)\n",
    "    logging.info(link)\n",
    "    t, a = get_title_author(link)\n",
    "    titles.extend(t)\n",
    "    authors.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_mask(title):\n",
    "    t = title.lower()\n",
    "    conditions = ['graph neural networks', 'gnns', 'gnn', 'graph', 'graph learning', 'graph embedding', 'network embedding']\n",
    "    return np.any([c in t for c in conditions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'markdown-output/2024-AAAI.txt', 'w', encoding='utf8') as fw:\n",
    "    for t, n in zip(titles, authors):\n",
    "        if graph_mask(t):\n",
    "            fw.write(f'1. **{t}**\\n\\n')\n",
    "            fw.write(f'    *{n}*\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = link_template.format(tracks[0])\n",
    "resp = requests.get(link, proxies=proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.find_all('div', class_='obj_article_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].h3.get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hasra Dodampegama, Mohan Sridharan'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].find_all('div', class_='authors')[0].get_text(strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = []\n",
    "articles = soup.find_all('h3', class_='title')\n",
    "for article in articles:\n",
    "    title = article.get_text(strip=True)\n",
    "    article_titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork',\n",
       " 'Reducing ANN-SNN Conversion Error through Residual Membrane Potential',\n",
       " 'Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning',\n",
       " 'Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse',\n",
       " 'A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks',\n",
       " 'A Machine with Short-Term, Episodic, and Semantic Memory Systems',\n",
       " 'Persuasion Strategies in Advertisements',\n",
       " 'Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild',\n",
       " 'AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work',\n",
       " 'ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks',\n",
       " 'Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs',\n",
       " 'Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition',\n",
       " 'Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis',\n",
       " 'CMNet: Contrastive Magnification Network for Micro-Expression Recognition',\n",
       " 'Disentangling Reafferent Effects by Doing Nothing',\n",
       " 'Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms',\n",
       " 'ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges',\n",
       " 'Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses',\n",
       " 'Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels',\n",
       " 'Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers',\n",
       " 'Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation',\n",
       " 'Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network',\n",
       " 'Layout Representation Learning with Spatial and Structural Hierarchies',\n",
       " 'Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization',\n",
       " 'Multi-Level Compositional Reasoning for Interactive Instruction Following',\n",
       " 'Self-Supervised Image Local Forgery Detection by JPEG Compression Trace',\n",
       " 'VASR: Visual Analogies of Situation Recognition',\n",
       " 'Parametric Surface Constrained Upsampler Network for Point Cloud',\n",
       " 'Explicit Invariant Feature Induced Cross-Domain Crowd Counting',\n",
       " 'Painterly Image Harmonization in Dual Domains',\n",
       " 'MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation',\n",
       " 'KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion',\n",
       " 'Deconstructed Generation-Based Zero-Shot Model',\n",
       " 'Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild',\n",
       " 'Amodal Instance Segmentation via Prior-Guided Expansion',\n",
       " 'SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting',\n",
       " 'Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction',\n",
       " 'Improving Dynamic HDR Imaging with Fusion Transformer',\n",
       " 'Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera',\n",
       " 'Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views',\n",
       " 'Scalable Spatial Memory for Scene Rendering and Navigation',\n",
       " 'Hybrid CNN-Transformer Feature Fusion for Single Image Deraining',\n",
       " 'MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection',\n",
       " 'Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval',\n",
       " 'DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning',\n",
       " 'Imperceptible Adversarial Attack via Invertible Neural Networks',\n",
       " 'Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding',\n",
       " 'User-Controllable Arbitrary Style Transfer via Entropy Regularization',\n",
       " 'Neural Architecture Search for Wide Spectrum Adversarial Robustness',\n",
       " 'Adversarial Alignment for Source Free Object Detection',\n",
       " 'Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR',\n",
       " 'OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement',\n",
       " 'Dual-Domain Attention for Image Deblurring',\n",
       " 'Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition',\n",
       " 'Improving Crowded Object Detection via Copy-Paste',\n",
       " 'Defending Backdoor Attacks on Vision Transformer via Patch Processing',\n",
       " 'Head-Free Lightweight Semantic Segmentation with Linear Transformer',\n",
       " 'Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning',\n",
       " 'Exploring Tuning Characteristics of Ventral Stream’s Neurons for Few-Shot Image Classification',\n",
       " 'Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning',\n",
       " 'PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers',\n",
       " 'Domain-General Crowd Counting in Unseen Scenarios',\n",
       " 'Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation',\n",
       " 'Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis',\n",
       " 'Target-Free Text-Guided Image Manipulation',\n",
       " 'One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation',\n",
       " 'Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint',\n",
       " 'Uncertainty-Aware Image Captioning',\n",
       " 'Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment',\n",
       " 'SEFormer: Structure Embedding Transformer for 3D Object Detection',\n",
       " 'Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation',\n",
       " 'Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision',\n",
       " 'Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism',\n",
       " 'Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations',\n",
       " 'Progressive Multi-View Human Mesh Recovery with Self-Supervision',\n",
       " 'Incremental Image De-raining via Associative Memory',\n",
       " 'Flexible 3D Lane Detection by Hierarchical Shape Matching',\n",
       " 'Underwater Ranker: Learn Which Is Better and How to Be Better',\n",
       " 'ShadowFormer: Global Context Helps Shadow Removal',\n",
       " 'RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs',\n",
       " 'RankDNN: Learning to Rank for Few-Shot Learning',\n",
       " 'Social Relation Reasoning Based on Triangular Constraints',\n",
       " 'CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention',\n",
       " 'Few-Shot Object Detection via Variational Feature Aggregation',\n",
       " 'Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization',\n",
       " 'Target-Aware Tracking with Long-Term Context Attention',\n",
       " 'Weakly-Supervised Camouflaged Object Detection with Scribble Annotations',\n",
       " 'Efficient Mirror Detection via Multi-Level Heterogeneous Learning',\n",
       " 'TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision',\n",
       " 'Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer',\n",
       " 'Parameter-Efficient Model Adaptation for Vision Transformers',\n",
       " 'DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images',\n",
       " 'GAM: Gradient Attention Module of Optimization for Point Clouds Analysis',\n",
       " 'Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions',\n",
       " 'Self-Emphasizing Network for Continuous Sign Language Recognition',\n",
       " 'Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution',\n",
       " 'PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples',\n",
       " 'High-Resolution Iterative Feedback Network for Camouflaged Object Detection',\n",
       " 'Leveraging Sub-class Discimination for Compositional Zero-Shot Learning',\n",
       " 'GPTR: Gestalt-Perception Transformer for Diagram Object Detection',\n",
       " 'Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning',\n",
       " 'ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation',\n",
       " 'NLIP: Noise-Robust Language-Image Pre-training',\n",
       " 'Symmetry-Aware Transformer-Based Mirror Detection',\n",
       " 'AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio',\n",
       " 'Boosting Point Clouds Rendering via Radiance Mapping',\n",
       " 'FreeEnricher: Enriching Face Landmarks without Additional Cost',\n",
       " 'PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues',\n",
       " 'Unifying Vision-Language Representation Space with Single-Tower Transformer',\n",
       " 'Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery',\n",
       " 'Semi-attention Partition for Occluded Person Re-identification',\n",
       " 'Fast Online Hashing with Multi-Label Projection',\n",
       " 'Fourier-Net: Fast Image Registration with Band-Limited Deformation',\n",
       " 'Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint',\n",
       " 'Multi-Modality Deep Network for Extreme Learned Image Compression',\n",
       " 'PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer',\n",
       " '3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation',\n",
       " 'FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer',\n",
       " 'Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning',\n",
       " 'Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection',\n",
       " 'Correlation Loss: Enforcing Correlation between Classification and Localization',\n",
       " 'GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps',\n",
       " '3D Human Pose Lifting with Grid Convolution',\n",
       " 'Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation',\n",
       " 'Frequency Selective Augmentation for Video Representation Learning',\n",
       " 'Pose-Guided 3D Human Generation in Indoor Scene',\n",
       " 'Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation',\n",
       " 'Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films',\n",
       " 'CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer',\n",
       " 'Simple and Effective Synthesis of Indoor 3D Scenes',\n",
       " 'MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection',\n",
       " 'InstanceFormer: An Online Video Instance Segmentation Framework',\n",
       " 'Pixel-Wise Warping for Deep Image Stitching',\n",
       " 'Learning to Learn Better for Video Object Segmentation',\n",
       " 'Curriculum Multi-Negative Augmentation for Debiased Video Grounding',\n",
       " 'Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency',\n",
       " 'MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels',\n",
       " 'Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud',\n",
       " 'Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task',\n",
       " 'Linking People across Text and Images Based on Social Relation Reasoning',\n",
       " 'ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing',\n",
       " 'SWBNet: A Stable White Balance Network for sRGB Images',\n",
       " 'Frequency Domain Disentanglement for Arbitrary Neural Style Transfer',\n",
       " 'Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation',\n",
       " 'CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation',\n",
       " 'Real-World Deep Local Motion Deblurring',\n",
       " 'Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective',\n",
       " 'Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos',\n",
       " 'FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks',\n",
       " 'Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing',\n",
       " 'Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration',\n",
       " 'Spatial-Spectral Transformer for Hyperspectral Image Denoising',\n",
       " 'Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval',\n",
       " 'Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding',\n",
       " 'NeAF: Learning Neural Angle Fields for Point Normal Estimation',\n",
       " 'CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
